{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tarfile\n",
    "import cv2\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '256_ObjectCategories/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folders = os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder_paths = []\n",
    "all_images = []\n",
    "all_classes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def make_square(image, min_size=img_size, fill_color=(0, 0, 0, 0)):\n",
    "    size = (min_size, min_size)\n",
    "    image.thumbnail(size, Image.ANTIALIAS)\n",
    "    background = Image.new('RGB', size, (255, 255, 255, 0))\n",
    "    background.paste(\n",
    "        image, (int((size[0] - image.size[0]) / 2), int((size[1] - image.size[1]) / 2))\n",
    "    )\n",
    "\n",
    "    new_img = np.array(background)\n",
    "    new_img.flatten()\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for folder in range(len(folders)):\n",
    "    folder_paths = path+str(folders[folder])+str('/')\n",
    "    \n",
    "    os.chdir(folder_paths)\n",
    "    image_in_folder = os.listdir()\n",
    "\n",
    "    for image in range(len(image_in_folder)):\n",
    "        img = Image.open(image_in_folder[image])\n",
    "        img = make_square(img)\n",
    "        \n",
    "        all_images.append(img.flatten()/255)\n",
    "        all_classes.append(folders[folder])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30607"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30607"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49152,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_images_df = np.asarray(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30607, 49152)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12035162224"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof(all_images_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_images_df1:112\n",
      "all_images_df2:112\n",
      "all_images_df3:112\n"
     ]
    }
   ],
   "source": [
    "all_images_df1 = all_images_df[:10000,:]\n",
    "all_images_df2 = all_images_df[10000:20000,:]\n",
    "all_images_df3 = all_images_df[20000:,:]\n",
    "print('all_images_df1:'+str(sys.getsizeof(all_images_df1)))\n",
    "print('all_images_df2:'+str(sys.getsizeof(all_images_df2)))\n",
    "print('all_images_df3:'+str(sys.getsizeof(all_images_df3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "picklepath = 'Caltech256/'\n",
    "os.chdir(picklepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_out = open(\"pickle_all_images_df1.pickle\",\"wb\")\n",
    "pickle.dump(all_images_df1, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"pickle_all_images_df2.pickle\",\"wb\")\n",
    "pickle.dump(all_images_df2, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"pickle_all_images_df3.pickle\",\"wb\")\n",
    "pickle.dump(all_images_df3, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"pickle_all_classes.pickle\",\"wb\")\n",
    "pickle.dump(all_classes, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 49152)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images_df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 49152)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10607, 49152)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images_df3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tarfile\n",
    "import cv2\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "picklepath = 'Caltech256/'\n",
    "os.chdir(picklepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_in = open(\"pickle_all_images_df1.pickle\",\"rb\")\n",
    "all_images_df1 = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"pickle_all_images_df2.pickle\",\"rb\")\n",
    "all_images_df2 = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"pickle_all_images_df3.pickle\",\"rb\")\n",
    "all_images_df3 = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"pickle_all_classes.pickle\",\"rb\")\n",
    "all_classes = pickle.load(pickle_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_images = np.concatenate((all_images_df1, all_images_df2,all_images_df3), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del all_images_df1\n",
    "del all_images_df2\n",
    "del all_images_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30607, 49152)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'001.ak47',\n",
       " '002.american-flag',\n",
       " '003.backpack',\n",
       " '004.baseball-bat',\n",
       " '005.baseball-glove',\n",
       " '006.basketball-hoop',\n",
       " '007.bat',\n",
       " '008.bathtub',\n",
       " '009.bear',\n",
       " '010.beer-mug',\n",
       " '011.billiards',\n",
       " '012.binoculars',\n",
       " '013.birdbath',\n",
       " '014.blimp',\n",
       " '015.bonsai-101',\n",
       " '016.boom-box',\n",
       " '017.bowling-ball',\n",
       " '018.bowling-pin',\n",
       " '019.boxing-glove',\n",
       " '020.brain-101',\n",
       " '021.breadmaker',\n",
       " '022.buddha-101',\n",
       " '023.bulldozer',\n",
       " '024.butterfly',\n",
       " '025.cactus',\n",
       " '026.cake',\n",
       " '027.calculator',\n",
       " '028.camel',\n",
       " '029.cannon',\n",
       " '030.canoe',\n",
       " '031.car-tire',\n",
       " '032.cartman',\n",
       " '033.cd',\n",
       " '034.centipede',\n",
       " '035.cereal-box',\n",
       " '036.chandelier-101',\n",
       " '037.chess-board',\n",
       " '038.chimp',\n",
       " '039.chopsticks',\n",
       " '040.cockroach',\n",
       " '041.coffee-mug',\n",
       " '042.coffin',\n",
       " '043.coin',\n",
       " '044.comet',\n",
       " '045.computer-keyboard',\n",
       " '046.computer-monitor',\n",
       " '047.computer-mouse',\n",
       " '048.conch',\n",
       " '049.cormorant',\n",
       " '050.covered-wagon',\n",
       " '051.cowboy-hat',\n",
       " '052.crab-101',\n",
       " '053.desk-globe',\n",
       " '054.diamond-ring',\n",
       " '055.dice',\n",
       " '056.dog',\n",
       " '057.dolphin-101',\n",
       " '058.doorknob',\n",
       " '059.drinking-straw',\n",
       " '060.duck',\n",
       " '061.dumb-bell',\n",
       " '062.eiffel-tower',\n",
       " '063.electric-guitar-101',\n",
       " '064.elephant-101',\n",
       " '065.elk',\n",
       " '066.ewer-101',\n",
       " '067.eyeglasses',\n",
       " '068.fern',\n",
       " '069.fighter-jet',\n",
       " '070.fire-extinguisher',\n",
       " '071.fire-hydrant',\n",
       " '072.fire-truck',\n",
       " '073.fireworks',\n",
       " '074.flashlight',\n",
       " '075.floppy-disk',\n",
       " '076.football-helmet',\n",
       " '077.french-horn',\n",
       " '078.fried-egg',\n",
       " '079.frisbee',\n",
       " '080.frog',\n",
       " '081.frying-pan',\n",
       " '082.galaxy',\n",
       " '083.gas-pump',\n",
       " '084.giraffe',\n",
       " '085.goat',\n",
       " '086.golden-gate-bridge',\n",
       " '087.goldfish',\n",
       " '088.golf-ball',\n",
       " '089.goose',\n",
       " '090.gorilla',\n",
       " '091.grand-piano-101',\n",
       " '092.grapes',\n",
       " '093.grasshopper',\n",
       " '094.guitar-pick',\n",
       " '095.hamburger',\n",
       " '096.hammock',\n",
       " '097.harmonica',\n",
       " '098.harp',\n",
       " '099.harpsichord',\n",
       " '100.hawksbill-101',\n",
       " '101.head-phones',\n",
       " '102.helicopter-101',\n",
       " '103.hibiscus',\n",
       " '104.homer-simpson',\n",
       " '105.horse',\n",
       " '106.horseshoe-crab',\n",
       " '107.hot-air-balloon',\n",
       " '108.hot-dog',\n",
       " '109.hot-tub',\n",
       " '110.hourglass',\n",
       " '111.house-fly',\n",
       " '112.human-skeleton',\n",
       " '113.hummingbird',\n",
       " '114.ibis-101',\n",
       " '115.ice-cream-cone',\n",
       " '116.iguana',\n",
       " '117.ipod',\n",
       " '118.iris',\n",
       " '119.jesus-christ',\n",
       " '120.joy-stick',\n",
       " '121.kangaroo-101',\n",
       " '122.kayak',\n",
       " '123.ketch-101',\n",
       " '124.killer-whale',\n",
       " '125.knife',\n",
       " '126.ladder',\n",
       " '127.laptop-101',\n",
       " '128.lathe',\n",
       " '129.leopards-101',\n",
       " '130.license-plate',\n",
       " '131.lightbulb',\n",
       " '132.light-house',\n",
       " '133.lightning',\n",
       " '134.llama-101',\n",
       " '135.mailbox',\n",
       " '136.mandolin',\n",
       " '137.mars',\n",
       " '138.mattress',\n",
       " '139.megaphone',\n",
       " '140.menorah-101',\n",
       " '141.microscope',\n",
       " '142.microwave',\n",
       " '143.minaret',\n",
       " '144.minotaur',\n",
       " '145.motorbikes-101',\n",
       " '146.mountain-bike',\n",
       " '147.mushroom',\n",
       " '148.mussels',\n",
       " '149.necktie',\n",
       " '150.octopus',\n",
       " '151.ostrich',\n",
       " '152.owl',\n",
       " '153.palm-pilot',\n",
       " '154.palm-tree',\n",
       " '155.paperclip',\n",
       " '156.paper-shredder',\n",
       " '157.pci-card',\n",
       " '158.penguin',\n",
       " '159.people',\n",
       " '160.pez-dispenser',\n",
       " '161.photocopier',\n",
       " '162.picnic-table',\n",
       " '163.playing-card',\n",
       " '164.porcupine',\n",
       " '165.pram',\n",
       " '166.praying-mantis',\n",
       " '167.pyramid',\n",
       " '168.raccoon',\n",
       " '169.radio-telescope',\n",
       " '170.rainbow',\n",
       " '171.refrigerator',\n",
       " '172.revolver-101',\n",
       " '173.rifle',\n",
       " '174.rotary-phone',\n",
       " '175.roulette-wheel',\n",
       " '176.saddle',\n",
       " '177.saturn',\n",
       " '178.school-bus',\n",
       " '179.scorpion-101',\n",
       " '180.screwdriver',\n",
       " '181.segway',\n",
       " '182.self-propelled-lawn-mower',\n",
       " '183.sextant',\n",
       " '184.sheet-music',\n",
       " '185.skateboard',\n",
       " '186.skunk',\n",
       " '187.skyscraper',\n",
       " '188.smokestack',\n",
       " '189.snail',\n",
       " '190.snake',\n",
       " '191.sneaker',\n",
       " '192.snowmobile',\n",
       " '193.soccer-ball',\n",
       " '194.socks',\n",
       " '195.soda-can',\n",
       " '196.spaghetti',\n",
       " '197.speed-boat',\n",
       " '198.spider',\n",
       " '199.spoon',\n",
       " '200.stained-glass',\n",
       " '201.starfish-101',\n",
       " '202.steering-wheel',\n",
       " '203.stirrups',\n",
       " '204.sunflower-101',\n",
       " '205.superman',\n",
       " '206.sushi',\n",
       " '207.swan',\n",
       " '208.swiss-army-knife',\n",
       " '209.sword',\n",
       " '210.syringe',\n",
       " '211.tambourine',\n",
       " '212.teapot',\n",
       " '213.teddy-bear',\n",
       " '214.teepee',\n",
       " '215.telephone-box',\n",
       " '216.tennis-ball',\n",
       " '217.tennis-court',\n",
       " '218.tennis-racket',\n",
       " '219.theodolite',\n",
       " '220.toaster',\n",
       " '221.tomato',\n",
       " '222.tombstone',\n",
       " '223.top-hat',\n",
       " '224.touring-bike',\n",
       " '225.tower-pisa',\n",
       " '226.traffic-light',\n",
       " '227.treadmill',\n",
       " '228.triceratops',\n",
       " '229.tricycle',\n",
       " '230.trilobite-101',\n",
       " '231.tripod',\n",
       " '232.t-shirt',\n",
       " '233.tuning-fork',\n",
       " '234.tweezer',\n",
       " '235.umbrella-101',\n",
       " '236.unicorn',\n",
       " '237.vcr',\n",
       " '238.video-projector',\n",
       " '239.washing-machine',\n",
       " '240.watch-101',\n",
       " '241.waterfall',\n",
       " '242.watermelon',\n",
       " '243.welding-mask',\n",
       " '244.wheelbarrow',\n",
       " '245.windmill',\n",
       " '246.wine-bottle',\n",
       " '247.xylophone',\n",
       " '248.yarmulke',\n",
       " '249.yo-yo',\n",
       " '250.zebra',\n",
       " '251.airplanes-101',\n",
       " '252.car-side-101',\n",
       " '253.faces-easy-101',\n",
       " '254.greyhound',\n",
       " '255.tennis-shoes',\n",
       " '256.toad',\n",
       " '257.clutter'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(all_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_classes = pd.get_dummies(all_classes) \n",
    "all_images = np.array(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_images, all_classes, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to reset the kernel a few times for this exercise because our RAM and our VRAM gets full quickly when running a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tarfile\n",
    "import cv2\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "img_size =  128\n",
    "picklepath = 'Caltech256/'\n",
    "os.chdir(picklepath)\n",
    "pickle_in = open(\"pickle_all_images_df1.pickle\",\"rb\")\n",
    "all_images_df1 = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"pickle_all_images_df2.pickle\",\"rb\")\n",
    "all_images_df2 = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"pickle_all_images_df3.pickle\",\"rb\")\n",
    "all_images_df3 = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"pickle_all_classes.pickle\",\"rb\")\n",
    "all_classes = pickle.load(pickle_in)\n",
    "all_images = np.concatenate((all_images_df1, all_images_df2,all_images_df3), axis=0)\n",
    "del all_images_df1\n",
    "del all_images_df2\n",
    "del all_images_df3\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "all_images = pd.DataFrame(all_images)\n",
    "X_test = all_images.groupby(all_classes).apply(lambda s: s.sample(4))\n",
    "test_index = X_test.index.levels[1].values\n",
    "\n",
    "X_test = X_test.reset_index(0).reset_index(drop=True)\n",
    "X_test = X_test.drop('level_0',axis = 1)\n",
    "X_train = all_images.drop(test_index)\n",
    "all_classes = pd.Series(all_classes)\n",
    "y_train = all_classes.drop(test_index)\n",
    "y_test = all_classes.iloc[test_index]\n",
    "\n",
    "y_train = pd.get_dummies(y_train) \n",
    "y_test = pd.get_dummies(y_test) \n",
    "\n",
    "X_train = X_train.as_matrix()\n",
    "X_test = X_test.as_matrix()\n",
    "\n",
    "del all_images\n",
    "X_train = X_train.reshape(-1,img_size,img_size,3)\n",
    "X_test = X_test.reshape(-1,img_size,img_size,3)\n",
    "path = 'Caltech256/256_ObjectCategories/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape data into Image Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1,img_size,img_size,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(-1,img_size,img_size,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generator = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "img = load_img(sample_image) \n",
    "x = img_to_array(img)  \n",
    "x = x.reshape((1,) + x.shape)  \n",
    "\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir='preview', save_prefix='butterfly', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 10:\n",
    "        break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder = \"Caltech256/preview/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "butterfly_filename = os.listdir(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generator.flow(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPool2D, AvgPool2D,Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time.sleep(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1849/1848 [==============================] - 120s 65ms/step - loss: 4.9184 - acc: 0.1118 - val_loss: 4.2616 - val_acc: 0.1868\n",
      "Epoch 2/10\n",
      "1849/1848 [==============================] - 113s 61ms/step - loss: 4.0484 - acc: 0.2182 - val_loss: 3.7186 - val_acc: 0.2782\n",
      "Epoch 3/10\n",
      "1849/1848 [==============================] - 116s 63ms/step - loss: 3.7122 - acc: 0.2597 - val_loss: 3.5049 - val_acc: 0.3123\n",
      "Epoch 4/10\n",
      "1849/1848 [==============================] - 114s 62ms/step - loss: 3.5210 - acc: 0.2893 - val_loss: 3.3274 - val_acc: 0.3356\n",
      "Epoch 5/10\n",
      "1849/1848 [==============================] - 115s 62ms/step - loss: 3.4270 - acc: 0.2979 - val_loss: 3.1808 - val_acc: 0.3531\n",
      "Epoch 6/10\n",
      "1849/1848 [==============================] - 115s 62ms/step - loss: 3.3192 - acc: 0.3175 - val_loss: 3.2082 - val_acc: 0.3599\n",
      "Epoch 7/10\n",
      "1849/1848 [==============================] - 113s 61ms/step - loss: 3.2660 - acc: 0.3191 - val_loss: 3.1258 - val_acc: 0.3492\n",
      "Epoch 8/10\n",
      "1849/1848 [==============================] - 118s 64ms/step - loss: 3.2252 - acc: 0.3268 - val_loss: 3.0744 - val_acc: 0.3609\n",
      "Epoch 9/10\n",
      "1849/1848 [==============================] - 114s 62ms/step - loss: 3.1816 - acc: 0.3369 - val_loss: 3.0143 - val_acc: 0.3891\n",
      "Epoch 10/10\n",
      "1849/1848 [==============================] - 113s 61ms/step - loss: 3.1172 - acc: 0.3425 - val_loss: 3.0277 - val_acc: 0.3706\n",
      "0 input_2\n",
      "1 conv2d_1\n",
      "2 batch_normalization_1\n",
      "3 activation_1\n",
      "4 conv2d_2\n",
      "5 batch_normalization_2\n",
      "6 activation_2\n",
      "7 conv2d_3\n",
      "8 batch_normalization_3\n",
      "9 activation_3\n",
      "10 max_pooling2d_1\n",
      "11 conv2d_4\n",
      "12 batch_normalization_4\n",
      "13 activation_4\n",
      "14 conv2d_5\n",
      "15 batch_normalization_5\n",
      "16 activation_5\n",
      "17 max_pooling2d_2\n",
      "18 conv2d_9\n",
      "19 batch_normalization_9\n",
      "20 activation_9\n",
      "21 conv2d_7\n",
      "22 conv2d_10\n",
      "23 batch_normalization_7\n",
      "24 batch_normalization_10\n",
      "25 activation_7\n",
      "26 activation_10\n",
      "27 average_pooling2d_1\n",
      "28 conv2d_6\n",
      "29 conv2d_8\n",
      "30 conv2d_11\n",
      "31 conv2d_12\n",
      "32 batch_normalization_6\n",
      "33 batch_normalization_8\n",
      "34 batch_normalization_11\n",
      "35 batch_normalization_12\n",
      "36 activation_6\n",
      "37 activation_8\n",
      "38 activation_11\n",
      "39 activation_12\n",
      "40 mixed0\n",
      "41 conv2d_16\n",
      "42 batch_normalization_16\n",
      "43 activation_16\n",
      "44 conv2d_14\n",
      "45 conv2d_17\n",
      "46 batch_normalization_14\n",
      "47 batch_normalization_17\n",
      "48 activation_14\n",
      "49 activation_17\n",
      "50 average_pooling2d_2\n",
      "51 conv2d_13\n",
      "52 conv2d_15\n",
      "53 conv2d_18\n",
      "54 conv2d_19\n",
      "55 batch_normalization_13\n",
      "56 batch_normalization_15\n",
      "57 batch_normalization_18\n",
      "58 batch_normalization_19\n",
      "59 activation_13\n",
      "60 activation_15\n",
      "61 activation_18\n",
      "62 activation_19\n",
      "63 mixed1\n",
      "64 conv2d_23\n",
      "65 batch_normalization_23\n",
      "66 activation_23\n",
      "67 conv2d_21\n",
      "68 conv2d_24\n",
      "69 batch_normalization_21\n",
      "70 batch_normalization_24\n",
      "71 activation_21\n",
      "72 activation_24\n",
      "73 average_pooling2d_3\n",
      "74 conv2d_20\n",
      "75 conv2d_22\n",
      "76 conv2d_25\n",
      "77 conv2d_26\n",
      "78 batch_normalization_20\n",
      "79 batch_normalization_22\n",
      "80 batch_normalization_25\n",
      "81 batch_normalization_26\n",
      "82 activation_20\n",
      "83 activation_22\n",
      "84 activation_25\n",
      "85 activation_26\n",
      "86 mixed2\n",
      "87 conv2d_28\n",
      "88 batch_normalization_28\n",
      "89 activation_28\n",
      "90 conv2d_29\n",
      "91 batch_normalization_29\n",
      "92 activation_29\n",
      "93 conv2d_27\n",
      "94 conv2d_30\n",
      "95 batch_normalization_27\n",
      "96 batch_normalization_30\n",
      "97 activation_27\n",
      "98 activation_30\n",
      "99 max_pooling2d_3\n",
      "100 mixed3\n",
      "101 conv2d_35\n",
      "102 batch_normalization_35\n",
      "103 activation_35\n",
      "104 conv2d_36\n",
      "105 batch_normalization_36\n",
      "106 activation_36\n",
      "107 conv2d_32\n",
      "108 conv2d_37\n",
      "109 batch_normalization_32\n",
      "110 batch_normalization_37\n",
      "111 activation_32\n",
      "112 activation_37\n",
      "113 conv2d_33\n",
      "114 conv2d_38\n",
      "115 batch_normalization_33\n",
      "116 batch_normalization_38\n",
      "117 activation_33\n",
      "118 activation_38\n",
      "119 average_pooling2d_4\n",
      "120 conv2d_31\n",
      "121 conv2d_34\n",
      "122 conv2d_39\n",
      "123 conv2d_40\n",
      "124 batch_normalization_31\n",
      "125 batch_normalization_34\n",
      "126 batch_normalization_39\n",
      "127 batch_normalization_40\n",
      "128 activation_31\n",
      "129 activation_34\n",
      "130 activation_39\n",
      "131 activation_40\n",
      "132 mixed4\n",
      "133 conv2d_45\n",
      "134 batch_normalization_45\n",
      "135 activation_45\n",
      "136 conv2d_46\n",
      "137 batch_normalization_46\n",
      "138 activation_46\n",
      "139 conv2d_42\n",
      "140 conv2d_47\n",
      "141 batch_normalization_42\n",
      "142 batch_normalization_47\n",
      "143 activation_42\n",
      "144 activation_47\n",
      "145 conv2d_43\n",
      "146 conv2d_48\n",
      "147 batch_normalization_43\n",
      "148 batch_normalization_48\n",
      "149 activation_43\n",
      "150 activation_48\n",
      "151 average_pooling2d_5\n",
      "152 conv2d_41\n",
      "153 conv2d_44\n",
      "154 conv2d_49\n",
      "155 conv2d_50\n",
      "156 batch_normalization_41\n",
      "157 batch_normalization_44\n",
      "158 batch_normalization_49\n",
      "159 batch_normalization_50\n",
      "160 activation_41\n",
      "161 activation_44\n",
      "162 activation_49\n",
      "163 activation_50\n",
      "164 mixed5\n",
      "165 conv2d_55\n",
      "166 batch_normalization_55\n",
      "167 activation_55\n",
      "168 conv2d_56\n",
      "169 batch_normalization_56\n",
      "170 activation_56\n",
      "171 conv2d_52\n",
      "172 conv2d_57\n",
      "173 batch_normalization_52\n",
      "174 batch_normalization_57\n",
      "175 activation_52\n",
      "176 activation_57\n",
      "177 conv2d_53\n",
      "178 conv2d_58\n",
      "179 batch_normalization_53\n",
      "180 batch_normalization_58\n",
      "181 activation_53\n",
      "182 activation_58\n",
      "183 average_pooling2d_6\n",
      "184 conv2d_51\n",
      "185 conv2d_54\n",
      "186 conv2d_59\n",
      "187 conv2d_60\n",
      "188 batch_normalization_51\n",
      "189 batch_normalization_54\n",
      "190 batch_normalization_59\n",
      "191 batch_normalization_60\n",
      "192 activation_51\n",
      "193 activation_54\n",
      "194 activation_59\n",
      "195 activation_60\n",
      "196 mixed6\n",
      "197 conv2d_65\n",
      "198 batch_normalization_65\n",
      "199 activation_65\n",
      "200 conv2d_66\n",
      "201 batch_normalization_66\n",
      "202 activation_66\n",
      "203 conv2d_62\n",
      "204 conv2d_67\n",
      "205 batch_normalization_62\n",
      "206 batch_normalization_67\n",
      "207 activation_62\n",
      "208 activation_67\n",
      "209 conv2d_63\n",
      "210 conv2d_68\n",
      "211 batch_normalization_63\n",
      "212 batch_normalization_68\n",
      "213 activation_63\n",
      "214 activation_68\n",
      "215 average_pooling2d_7\n",
      "216 conv2d_61\n",
      "217 conv2d_64\n",
      "218 conv2d_69\n",
      "219 conv2d_70\n",
      "220 batch_normalization_61\n",
      "221 batch_normalization_64\n",
      "222 batch_normalization_69\n",
      "223 batch_normalization_70\n",
      "224 activation_61\n",
      "225 activation_64\n",
      "226 activation_69\n",
      "227 activation_70\n",
      "228 mixed7\n",
      "229 conv2d_73\n",
      "230 batch_normalization_73\n",
      "231 activation_73\n",
      "232 conv2d_74\n",
      "233 batch_normalization_74\n",
      "234 activation_74\n",
      "235 conv2d_71\n",
      "236 conv2d_75\n",
      "237 batch_normalization_71\n",
      "238 batch_normalization_75\n",
      "239 activation_71\n",
      "240 activation_75\n",
      "241 conv2d_72\n",
      "242 conv2d_76\n",
      "243 batch_normalization_72\n",
      "244 batch_normalization_76\n",
      "245 activation_72\n",
      "246 activation_76\n",
      "247 max_pooling2d_4\n",
      "248 mixed8\n",
      "249 conv2d_81\n",
      "250 batch_normalization_81\n",
      "251 activation_81\n",
      "252 conv2d_78\n",
      "253 conv2d_82\n",
      "254 batch_normalization_78\n",
      "255 batch_normalization_82\n",
      "256 activation_78\n",
      "257 activation_82\n",
      "258 conv2d_79\n",
      "259 conv2d_80\n",
      "260 conv2d_83\n",
      "261 conv2d_84\n",
      "262 average_pooling2d_8\n",
      "263 conv2d_77\n",
      "264 batch_normalization_79\n",
      "265 batch_normalization_80\n",
      "266 batch_normalization_83\n",
      "267 batch_normalization_84\n",
      "268 conv2d_85\n",
      "269 batch_normalization_77\n",
      "270 activation_79\n",
      "271 activation_80\n",
      "272 activation_83\n",
      "273 activation_84\n",
      "274 batch_normalization_85\n",
      "275 activation_77\n",
      "276 mixed9_0\n",
      "277 concatenate_1\n",
      "278 activation_85\n",
      "279 mixed9\n",
      "280 conv2d_90\n",
      "281 batch_normalization_90\n",
      "282 activation_90\n",
      "283 conv2d_87\n",
      "284 conv2d_91\n",
      "285 batch_normalization_87\n",
      "286 batch_normalization_91\n",
      "287 activation_87\n",
      "288 activation_91\n",
      "289 conv2d_88\n",
      "290 conv2d_89\n",
      "291 conv2d_92\n",
      "292 conv2d_93\n",
      "293 average_pooling2d_9\n",
      "294 conv2d_86\n",
      "295 batch_normalization_88\n",
      "296 batch_normalization_89\n",
      "297 batch_normalization_92\n",
      "298 batch_normalization_93\n",
      "299 conv2d_94\n",
      "300 batch_normalization_86\n",
      "301 activation_88\n",
      "302 activation_89\n",
      "303 activation_92\n",
      "304 activation_93\n",
      "305 batch_normalization_94\n",
      "306 activation_86\n",
      "307 mixed9_1\n",
      "308 concatenate_2\n",
      "309 activation_94\n",
      "310 mixed10\n",
      "Epoch 1/10\n",
      "1849/1848 [==============================] - 166s 90ms/step - loss: 2.9347 - acc: 0.3590 - val_loss: 2.4167 - val_acc: 0.4689\n",
      "Epoch 2/10\n",
      "1849/1848 [==============================] - 161s 87ms/step - loss: 2.4460 - acc: 0.4444 - val_loss: 2.2616 - val_acc: 0.5233\n",
      "Epoch 3/10\n",
      "1849/1848 [==============================] - 162s 87ms/step - loss: 2.2887 - acc: 0.4746 - val_loss: 2.1873 - val_acc: 0.5204\n",
      "Epoch 4/10\n",
      "1849/1848 [==============================] - 162s 87ms/step - loss: 2.1765 - acc: 0.4961 - val_loss: 2.1417 - val_acc: 0.5477\n",
      "Epoch 5/10\n",
      "1849/1848 [==============================] - 162s 87ms/step - loss: 2.0912 - acc: 0.5104 - val_loss: 2.0798 - val_acc: 0.5302\n",
      "Epoch 6/10\n",
      "1849/1848 [==============================] - 161s 87ms/step - loss: 2.0302 - acc: 0.5236 - val_loss: 2.1800 - val_acc: 0.5321\n",
      "Epoch 7/10\n",
      "1849/1848 [==============================] - 161s 87ms/step - loss: 1.9699 - acc: 0.5306 - val_loss: 2.0145 - val_acc: 0.5642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "1849/1848 [==============================] - 162s 87ms/step - loss: 1.9096 - acc: 0.5459 - val_loss: 2.0545 - val_acc: 0.5545\n",
      "Epoch 9/10\n",
      "1849/1848 [==============================] - 162s 87ms/step - loss: 1.8733 - acc: 0.5507 - val_loss: 2.0581 - val_acc: 0.5700\n",
      "Epoch 10/10\n",
      "1849/1848 [==============================] - 162s 87ms/step - loss: 1.8048 - acc: 0.5653 - val_loss: 2.0298 - val_acc: 0.5700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2bc0135bef0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(257, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "adam = Adam(lr=0.0001)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(generator.flow(X_train, y_train.values, batch_size=batch_size),len(X_train) / batch_size, epochs=10,verbose=1,validation_data=(X_test, y_test.values))\n",
    "\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name)\n",
    "\n",
    "for layer in model.layers[:249]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(generator.flow(X_train, y_train.values, batch_size=batch_size),len(X_train) / batch_size, epochs=10,verbose=1,validation_data=(X_test, y_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1849/1848 [==============================] - 199s 108ms/step - loss: 2.0609 - acc: 0.5143 - val_loss: 2.0445 - val_acc: 0.5496\n",
      "Epoch 2/20\n",
      "1849/1848 [==============================] - 192s 104ms/step - loss: 1.7230 - acc: 0.5801 - val_loss: 2.0046 - val_acc: 0.5710\n",
      "Epoch 3/20\n",
      "1849/1848 [==============================] - 193s 104ms/step - loss: 1.6193 - acc: 0.6001 - val_loss: 1.9723 - val_acc: 0.5856\n",
      "Epoch 4/20\n",
      "1849/1848 [==============================] - 193s 104ms/step - loss: 1.5394 - acc: 0.6176 - val_loss: 1.9001 - val_acc: 0.5953\n",
      "Epoch 5/20\n",
      "1849/1848 [==============================] - 193s 104ms/step - loss: 1.4665 - acc: 0.6310 - val_loss: 1.8551 - val_acc: 0.6060\n",
      "Epoch 6/20\n",
      "1849/1848 [==============================] - 193s 104ms/step - loss: 1.4170 - acc: 0.6454 - val_loss: 1.8237 - val_acc: 0.6235\n",
      "Epoch 7/20\n",
      "1849/1848 [==============================] - 193s 105ms/step - loss: 1.3774 - acc: 0.6490 - val_loss: 1.8515 - val_acc: 0.6158\n",
      "Epoch 8/20\n",
      "1849/1848 [==============================] - 193s 104ms/step - loss: 1.3244 - acc: 0.6625 - val_loss: 1.8746 - val_acc: 0.6187\n",
      "Epoch 9/20\n",
      "1849/1848 [==============================] - 193s 105ms/step - loss: 1.2839 - acc: 0.6715 - val_loss: 1.8688 - val_acc: 0.6294\n",
      "Epoch 10/20\n",
      "1849/1848 [==============================] - 193s 104ms/step - loss: 1.2328 - acc: 0.6781 - val_loss: 1.8756 - val_acc: 0.6255\n",
      "Epoch 11/20\n",
      "1849/1848 [==============================] - 193s 105ms/step - loss: 1.1964 - acc: 0.6893 - val_loss: 1.8784 - val_acc: 0.6265\n",
      "Epoch 12/20\n",
      "1849/1848 [==============================] - 193s 104ms/step - loss: 1.1662 - acc: 0.6952 - val_loss: 1.8509 - val_acc: 0.6226\n",
      "Epoch 13/20\n",
      "1849/1848 [==============================] - 193s 105ms/step - loss: 1.1302 - acc: 0.7043 - val_loss: 1.9220 - val_acc: 0.6245\n",
      "Epoch 14/20\n",
      "1849/1848 [==============================] - 193s 104ms/step - loss: 1.0844 - acc: 0.7114 - val_loss: 1.9326 - val_acc: 0.6362\n",
      "Epoch 15/20\n",
      "1849/1848 [==============================] - 193s 105ms/step - loss: 1.0638 - acc: 0.7176 - val_loss: 1.8851 - val_acc: 0.6294\n",
      "Epoch 16/20\n",
      "1849/1848 [==============================] - 193s 104ms/step - loss: 1.0501 - acc: 0.7227 - val_loss: 1.8832 - val_acc: 0.6284\n",
      "Epoch 17/20\n",
      "1849/1848 [==============================] - 193s 105ms/step - loss: 1.0082 - acc: 0.7294 - val_loss: 1.9093 - val_acc: 0.6284\n",
      "Epoch 18/20\n",
      "1849/1848 [==============================] - 193s 104ms/step - loss: 1.0024 - acc: 0.7305 - val_loss: 1.9441 - val_acc: 0.6167\n",
      "Epoch 19/20\n",
      "1849/1848 [==============================] - 193s 105ms/step - loss: 0.9649 - acc: 0.7413 - val_loss: 1.9556 - val_acc: 0.6235\n",
      "Epoch 20/20\n",
      "1849/1848 [==============================] - 193s 104ms/step - loss: 0.9438 - acc: 0.7483 - val_loss: 1.9542 - val_acc: 0.6381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2bbe563ef98>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for layer in model.layers[:200]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[200:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "time.sleep(100)\n",
    "\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(generator.flow(X_train, y_train.values, batch_size=batch_size),len(X_train) / batch_size, epochs=20,verbose=1,validation_data=(X_test, y_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.save('inception_model.h5') \n",
    "del model  \n",
    "model = load_model('inception_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1028/1028 [==============================] - 4s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9541673719419115, 0.63813229571984431]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x = X_test, y = y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Accuracy:63%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time.sleep(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "463/462 [==============================] - 107s 231ms/step - loss: 4.9141 - acc: 0.1453 - val_loss: 4.0190 - val_acc: 0.2665\n",
      "Epoch 2/20\n",
      "463/462 [==============================] - 102s 220ms/step - loss: 3.9330 - acc: 0.2881 - val_loss: 3.3587 - val_acc: 0.3531\n",
      "Epoch 3/20\n",
      "463/462 [==============================] - 102s 220ms/step - loss: 3.5136 - acc: 0.3346 - val_loss: 3.0624 - val_acc: 0.3911\n",
      "Epoch 4/20\n",
      "463/462 [==============================] - 102s 220ms/step - loss: 3.3008 - acc: 0.3568 - val_loss: 2.9308 - val_acc: 0.4018\n",
      "Epoch 5/20\n",
      "463/462 [==============================] - 102s 220ms/step - loss: 3.1637 - acc: 0.3783 - val_loss: 2.8005 - val_acc: 0.4222\n",
      "Epoch 6/20\n",
      "463/462 [==============================] - 102s 220ms/step - loss: 3.0639 - acc: 0.3886 - val_loss: 2.7226 - val_acc: 0.4329\n",
      "Epoch 7/20\n",
      "463/462 [==============================] - 102s 221ms/step - loss: 2.9681 - acc: 0.3976 - val_loss: 2.6915 - val_acc: 0.4368\n",
      "Epoch 8/20\n",
      "463/462 [==============================] - 102s 221ms/step - loss: 2.9166 - acc: 0.4053 - val_loss: 2.6350 - val_acc: 0.4270\n",
      "Epoch 9/20\n",
      "463/462 [==============================] - 102s 220ms/step - loss: 2.8665 - acc: 0.4109 - val_loss: 2.6088 - val_acc: 0.4377\n",
      "Epoch 10/20\n",
      "463/462 [==============================] - 102s 221ms/step - loss: 2.8153 - acc: 0.4198 - val_loss: 2.5577 - val_acc: 0.4494\n",
      "Epoch 11/20\n",
      "463/462 [==============================] - 102s 220ms/step - loss: 2.7658 - acc: 0.4254 - val_loss: 2.5547 - val_acc: 0.4523\n",
      "Epoch 12/20\n",
      "463/462 [==============================] - 102s 220ms/step - loss: 2.7447 - acc: 0.4283 - val_loss: 2.5210 - val_acc: 0.4582\n",
      "Epoch 13/20\n",
      "463/462 [==============================] - 102s 221ms/step - loss: 2.7070 - acc: 0.4353 - val_loss: 2.5138 - val_acc: 0.4621\n",
      "Epoch 14/20\n",
      "463/462 [==============================] - 102s 221ms/step - loss: 2.6880 - acc: 0.4383 - val_loss: 2.4869 - val_acc: 0.4533\n",
      "Epoch 15/20\n",
      "463/462 [==============================] - 102s 220ms/step - loss: 2.6636 - acc: 0.4429 - val_loss: 2.4647 - val_acc: 0.4708\n",
      "Epoch 16/20\n",
      "463/462 [==============================] - 102s 220ms/step - loss: 2.6443 - acc: 0.4429 - val_loss: 2.4283 - val_acc: 0.4708\n",
      "Epoch 17/20\n",
      "463/462 [==============================] - 102s 220ms/step - loss: 2.6177 - acc: 0.4468 - val_loss: 2.4241 - val_acc: 0.4796\n",
      "Epoch 18/20\n",
      "463/462 [==============================] - 102s 221ms/step - loss: 2.5988 - acc: 0.4536 - val_loss: 2.4261 - val_acc: 0.4689\n",
      "Epoch 19/20\n",
      "463/462 [==============================] - 102s 220ms/step - loss: 2.5670 - acc: 0.4552 - val_loss: 2.3951 - val_acc: 0.4786\n",
      "Epoch 20/20\n",
      "463/462 [==============================] - 102s 220ms/step - loss: 2.5523 - acc: 0.4611 - val_loss: 2.4193 - val_acc: 0.4767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2bcd3265ba8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "base_model = InceptionResNetV2(weights='imagenet', include_top=False)\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(257, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "adam = Adam(lr=0.0001)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(generator.flow(X_train, y_train.values, batch_size=batch_size),len(X_train) / batch_size, epochs=20,verbose=1,validation_data=(X_test, y_test.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_3\n",
      "1 conv2d_95\n",
      "2 batch_normalization_95\n",
      "3 activation_95\n",
      "4 conv2d_96\n",
      "5 batch_normalization_96\n",
      "6 activation_96\n",
      "7 conv2d_97\n",
      "8 batch_normalization_97\n",
      "9 activation_97\n",
      "10 max_pooling2d_5\n",
      "11 conv2d_98\n",
      "12 batch_normalization_98\n",
      "13 activation_98\n",
      "14 conv2d_99\n",
      "15 batch_normalization_99\n",
      "16 activation_99\n",
      "17 max_pooling2d_6\n",
      "18 conv2d_103\n",
      "19 batch_normalization_103\n",
      "20 activation_103\n",
      "21 conv2d_101\n",
      "22 conv2d_104\n",
      "23 batch_normalization_101\n",
      "24 batch_normalization_104\n",
      "25 activation_101\n",
      "26 activation_104\n",
      "27 average_pooling2d_10\n",
      "28 conv2d_100\n",
      "29 conv2d_102\n",
      "30 conv2d_105\n",
      "31 conv2d_106\n",
      "32 batch_normalization_100\n",
      "33 batch_normalization_102\n",
      "34 batch_normalization_105\n",
      "35 batch_normalization_106\n",
      "36 activation_100\n",
      "37 activation_102\n",
      "38 activation_105\n",
      "39 activation_106\n",
      "40 mixed_5b\n",
      "41 conv2d_110\n",
      "42 batch_normalization_110\n",
      "43 activation_110\n",
      "44 conv2d_108\n",
      "45 conv2d_111\n",
      "46 batch_normalization_108\n",
      "47 batch_normalization_111\n",
      "48 activation_108\n",
      "49 activation_111\n",
      "50 conv2d_107\n",
      "51 conv2d_109\n",
      "52 conv2d_112\n",
      "53 batch_normalization_107\n",
      "54 batch_normalization_109\n",
      "55 batch_normalization_112\n",
      "56 activation_107\n",
      "57 activation_109\n",
      "58 activation_112\n",
      "59 block35_1_mixed\n",
      "60 block35_1_conv\n",
      "61 block35_1\n",
      "62 block35_1_ac\n",
      "63 conv2d_116\n",
      "64 batch_normalization_116\n",
      "65 activation_116\n",
      "66 conv2d_114\n",
      "67 conv2d_117\n",
      "68 batch_normalization_114\n",
      "69 batch_normalization_117\n",
      "70 activation_114\n",
      "71 activation_117\n",
      "72 conv2d_113\n",
      "73 conv2d_115\n",
      "74 conv2d_118\n",
      "75 batch_normalization_113\n",
      "76 batch_normalization_115\n",
      "77 batch_normalization_118\n",
      "78 activation_113\n",
      "79 activation_115\n",
      "80 activation_118\n",
      "81 block35_2_mixed\n",
      "82 block35_2_conv\n",
      "83 block35_2\n",
      "84 block35_2_ac\n",
      "85 conv2d_122\n",
      "86 batch_normalization_122\n",
      "87 activation_122\n",
      "88 conv2d_120\n",
      "89 conv2d_123\n",
      "90 batch_normalization_120\n",
      "91 batch_normalization_123\n",
      "92 activation_120\n",
      "93 activation_123\n",
      "94 conv2d_119\n",
      "95 conv2d_121\n",
      "96 conv2d_124\n",
      "97 batch_normalization_119\n",
      "98 batch_normalization_121\n",
      "99 batch_normalization_124\n",
      "100 activation_119\n",
      "101 activation_121\n",
      "102 activation_124\n",
      "103 block35_3_mixed\n",
      "104 block35_3_conv\n",
      "105 block35_3\n",
      "106 block35_3_ac\n",
      "107 conv2d_128\n",
      "108 batch_normalization_128\n",
      "109 activation_128\n",
      "110 conv2d_126\n",
      "111 conv2d_129\n",
      "112 batch_normalization_126\n",
      "113 batch_normalization_129\n",
      "114 activation_126\n",
      "115 activation_129\n",
      "116 conv2d_125\n",
      "117 conv2d_127\n",
      "118 conv2d_130\n",
      "119 batch_normalization_125\n",
      "120 batch_normalization_127\n",
      "121 batch_normalization_130\n",
      "122 activation_125\n",
      "123 activation_127\n",
      "124 activation_130\n",
      "125 block35_4_mixed\n",
      "126 block35_4_conv\n",
      "127 block35_4\n",
      "128 block35_4_ac\n",
      "129 conv2d_134\n",
      "130 batch_normalization_134\n",
      "131 activation_134\n",
      "132 conv2d_132\n",
      "133 conv2d_135\n",
      "134 batch_normalization_132\n",
      "135 batch_normalization_135\n",
      "136 activation_132\n",
      "137 activation_135\n",
      "138 conv2d_131\n",
      "139 conv2d_133\n",
      "140 conv2d_136\n",
      "141 batch_normalization_131\n",
      "142 batch_normalization_133\n",
      "143 batch_normalization_136\n",
      "144 activation_131\n",
      "145 activation_133\n",
      "146 activation_136\n",
      "147 block35_5_mixed\n",
      "148 block35_5_conv\n",
      "149 block35_5\n",
      "150 block35_5_ac\n",
      "151 conv2d_140\n",
      "152 batch_normalization_140\n",
      "153 activation_140\n",
      "154 conv2d_138\n",
      "155 conv2d_141\n",
      "156 batch_normalization_138\n",
      "157 batch_normalization_141\n",
      "158 activation_138\n",
      "159 activation_141\n",
      "160 conv2d_137\n",
      "161 conv2d_139\n",
      "162 conv2d_142\n",
      "163 batch_normalization_137\n",
      "164 batch_normalization_139\n",
      "165 batch_normalization_142\n",
      "166 activation_137\n",
      "167 activation_139\n",
      "168 activation_142\n",
      "169 block35_6_mixed\n",
      "170 block35_6_conv\n",
      "171 block35_6\n",
      "172 block35_6_ac\n",
      "173 conv2d_146\n",
      "174 batch_normalization_146\n",
      "175 activation_146\n",
      "176 conv2d_144\n",
      "177 conv2d_147\n",
      "178 batch_normalization_144\n",
      "179 batch_normalization_147\n",
      "180 activation_144\n",
      "181 activation_147\n",
      "182 conv2d_143\n",
      "183 conv2d_145\n",
      "184 conv2d_148\n",
      "185 batch_normalization_143\n",
      "186 batch_normalization_145\n",
      "187 batch_normalization_148\n",
      "188 activation_143\n",
      "189 activation_145\n",
      "190 activation_148\n",
      "191 block35_7_mixed\n",
      "192 block35_7_conv\n",
      "193 block35_7\n",
      "194 block35_7_ac\n",
      "195 conv2d_152\n",
      "196 batch_normalization_152\n",
      "197 activation_152\n",
      "198 conv2d_150\n",
      "199 conv2d_153\n",
      "200 batch_normalization_150\n",
      "201 batch_normalization_153\n",
      "202 activation_150\n",
      "203 activation_153\n",
      "204 conv2d_149\n",
      "205 conv2d_151\n",
      "206 conv2d_154\n",
      "207 batch_normalization_149\n",
      "208 batch_normalization_151\n",
      "209 batch_normalization_154\n",
      "210 activation_149\n",
      "211 activation_151\n",
      "212 activation_154\n",
      "213 block35_8_mixed\n",
      "214 block35_8_conv\n",
      "215 block35_8\n",
      "216 block35_8_ac\n",
      "217 conv2d_158\n",
      "218 batch_normalization_158\n",
      "219 activation_158\n",
      "220 conv2d_156\n",
      "221 conv2d_159\n",
      "222 batch_normalization_156\n",
      "223 batch_normalization_159\n",
      "224 activation_156\n",
      "225 activation_159\n",
      "226 conv2d_155\n",
      "227 conv2d_157\n",
      "228 conv2d_160\n",
      "229 batch_normalization_155\n",
      "230 batch_normalization_157\n",
      "231 batch_normalization_160\n",
      "232 activation_155\n",
      "233 activation_157\n",
      "234 activation_160\n",
      "235 block35_9_mixed\n",
      "236 block35_9_conv\n",
      "237 block35_9\n",
      "238 block35_9_ac\n",
      "239 conv2d_164\n",
      "240 batch_normalization_164\n",
      "241 activation_164\n",
      "242 conv2d_162\n",
      "243 conv2d_165\n",
      "244 batch_normalization_162\n",
      "245 batch_normalization_165\n",
      "246 activation_162\n",
      "247 activation_165\n",
      "248 conv2d_161\n",
      "249 conv2d_163\n",
      "250 conv2d_166\n",
      "251 batch_normalization_161\n",
      "252 batch_normalization_163\n",
      "253 batch_normalization_166\n",
      "254 activation_161\n",
      "255 activation_163\n",
      "256 activation_166\n",
      "257 block35_10_mixed\n",
      "258 block35_10_conv\n",
      "259 block35_10\n",
      "260 block35_10_ac\n",
      "261 conv2d_168\n",
      "262 batch_normalization_168\n",
      "263 activation_168\n",
      "264 conv2d_169\n",
      "265 batch_normalization_169\n",
      "266 activation_169\n",
      "267 conv2d_167\n",
      "268 conv2d_170\n",
      "269 batch_normalization_167\n",
      "270 batch_normalization_170\n",
      "271 activation_167\n",
      "272 activation_170\n",
      "273 max_pooling2d_7\n",
      "274 mixed_6a\n",
      "275 conv2d_172\n",
      "276 batch_normalization_172\n",
      "277 activation_172\n",
      "278 conv2d_173\n",
      "279 batch_normalization_173\n",
      "280 activation_173\n",
      "281 conv2d_171\n",
      "282 conv2d_174\n",
      "283 batch_normalization_171\n",
      "284 batch_normalization_174\n",
      "285 activation_171\n",
      "286 activation_174\n",
      "287 block17_1_mixed\n",
      "288 block17_1_conv\n",
      "289 block17_1\n",
      "290 block17_1_ac\n",
      "291 conv2d_176\n",
      "292 batch_normalization_176\n",
      "293 activation_176\n",
      "294 conv2d_177\n",
      "295 batch_normalization_177\n",
      "296 activation_177\n",
      "297 conv2d_175\n",
      "298 conv2d_178\n",
      "299 batch_normalization_175\n",
      "300 batch_normalization_178\n",
      "301 activation_175\n",
      "302 activation_178\n",
      "303 block17_2_mixed\n",
      "304 block17_2_conv\n",
      "305 block17_2\n",
      "306 block17_2_ac\n",
      "307 conv2d_180\n",
      "308 batch_normalization_180\n",
      "309 activation_180\n",
      "310 conv2d_181\n",
      "311 batch_normalization_181\n",
      "312 activation_181\n",
      "313 conv2d_179\n",
      "314 conv2d_182\n",
      "315 batch_normalization_179\n",
      "316 batch_normalization_182\n",
      "317 activation_179\n",
      "318 activation_182\n",
      "319 block17_3_mixed\n",
      "320 block17_3_conv\n",
      "321 block17_3\n",
      "322 block17_3_ac\n",
      "323 conv2d_184\n",
      "324 batch_normalization_184\n",
      "325 activation_184\n",
      "326 conv2d_185\n",
      "327 batch_normalization_185\n",
      "328 activation_185\n",
      "329 conv2d_183\n",
      "330 conv2d_186\n",
      "331 batch_normalization_183\n",
      "332 batch_normalization_186\n",
      "333 activation_183\n",
      "334 activation_186\n",
      "335 block17_4_mixed\n",
      "336 block17_4_conv\n",
      "337 block17_4\n",
      "338 block17_4_ac\n",
      "339 conv2d_188\n",
      "340 batch_normalization_188\n",
      "341 activation_188\n",
      "342 conv2d_189\n",
      "343 batch_normalization_189\n",
      "344 activation_189\n",
      "345 conv2d_187\n",
      "346 conv2d_190\n",
      "347 batch_normalization_187\n",
      "348 batch_normalization_190\n",
      "349 activation_187\n",
      "350 activation_190\n",
      "351 block17_5_mixed\n",
      "352 block17_5_conv\n",
      "353 block17_5\n",
      "354 block17_5_ac\n",
      "355 conv2d_192\n",
      "356 batch_normalization_192\n",
      "357 activation_192\n",
      "358 conv2d_193\n",
      "359 batch_normalization_193\n",
      "360 activation_193\n",
      "361 conv2d_191\n",
      "362 conv2d_194\n",
      "363 batch_normalization_191\n",
      "364 batch_normalization_194\n",
      "365 activation_191\n",
      "366 activation_194\n",
      "367 block17_6_mixed\n",
      "368 block17_6_conv\n",
      "369 block17_6\n",
      "370 block17_6_ac\n",
      "371 conv2d_196\n",
      "372 batch_normalization_196\n",
      "373 activation_196\n",
      "374 conv2d_197\n",
      "375 batch_normalization_197\n",
      "376 activation_197\n",
      "377 conv2d_195\n",
      "378 conv2d_198\n",
      "379 batch_normalization_195\n",
      "380 batch_normalization_198\n",
      "381 activation_195\n",
      "382 activation_198\n",
      "383 block17_7_mixed\n",
      "384 block17_7_conv\n",
      "385 block17_7\n",
      "386 block17_7_ac\n",
      "387 conv2d_200\n",
      "388 batch_normalization_200\n",
      "389 activation_200\n",
      "390 conv2d_201\n",
      "391 batch_normalization_201\n",
      "392 activation_201\n",
      "393 conv2d_199\n",
      "394 conv2d_202\n",
      "395 batch_normalization_199\n",
      "396 batch_normalization_202\n",
      "397 activation_199\n",
      "398 activation_202\n",
      "399 block17_8_mixed\n",
      "400 block17_8_conv\n",
      "401 block17_8\n",
      "402 block17_8_ac\n",
      "403 conv2d_204\n",
      "404 batch_normalization_204\n",
      "405 activation_204\n",
      "406 conv2d_205\n",
      "407 batch_normalization_205\n",
      "408 activation_205\n",
      "409 conv2d_203\n",
      "410 conv2d_206\n",
      "411 batch_normalization_203\n",
      "412 batch_normalization_206\n",
      "413 activation_203\n",
      "414 activation_206\n",
      "415 block17_9_mixed\n",
      "416 block17_9_conv\n",
      "417 block17_9\n",
      "418 block17_9_ac\n",
      "419 conv2d_208\n",
      "420 batch_normalization_208\n",
      "421 activation_208\n",
      "422 conv2d_209\n",
      "423 batch_normalization_209\n",
      "424 activation_209\n",
      "425 conv2d_207\n",
      "426 conv2d_210\n",
      "427 batch_normalization_207\n",
      "428 batch_normalization_210\n",
      "429 activation_207\n",
      "430 activation_210\n",
      "431 block17_10_mixed\n",
      "432 block17_10_conv\n",
      "433 block17_10\n",
      "434 block17_10_ac\n",
      "435 conv2d_212\n",
      "436 batch_normalization_212\n",
      "437 activation_212\n",
      "438 conv2d_213\n",
      "439 batch_normalization_213\n",
      "440 activation_213\n",
      "441 conv2d_211\n",
      "442 conv2d_214\n",
      "443 batch_normalization_211\n",
      "444 batch_normalization_214\n",
      "445 activation_211\n",
      "446 activation_214\n",
      "447 block17_11_mixed\n",
      "448 block17_11_conv\n",
      "449 block17_11\n",
      "450 block17_11_ac\n",
      "451 conv2d_216\n",
      "452 batch_normalization_216\n",
      "453 activation_216\n",
      "454 conv2d_217\n",
      "455 batch_normalization_217\n",
      "456 activation_217\n",
      "457 conv2d_215\n",
      "458 conv2d_218\n",
      "459 batch_normalization_215\n",
      "460 batch_normalization_218\n",
      "461 activation_215\n",
      "462 activation_218\n",
      "463 block17_12_mixed\n",
      "464 block17_12_conv\n",
      "465 block17_12\n",
      "466 block17_12_ac\n",
      "467 conv2d_220\n",
      "468 batch_normalization_220\n",
      "469 activation_220\n",
      "470 conv2d_221\n",
      "471 batch_normalization_221\n",
      "472 activation_221\n",
      "473 conv2d_219\n",
      "474 conv2d_222\n",
      "475 batch_normalization_219\n",
      "476 batch_normalization_222\n",
      "477 activation_219\n",
      "478 activation_222\n",
      "479 block17_13_mixed\n",
      "480 block17_13_conv\n",
      "481 block17_13\n",
      "482 block17_13_ac\n",
      "483 conv2d_224\n",
      "484 batch_normalization_224\n",
      "485 activation_224\n",
      "486 conv2d_225\n",
      "487 batch_normalization_225\n",
      "488 activation_225\n",
      "489 conv2d_223\n",
      "490 conv2d_226\n",
      "491 batch_normalization_223\n",
      "492 batch_normalization_226\n",
      "493 activation_223\n",
      "494 activation_226\n",
      "495 block17_14_mixed\n",
      "496 block17_14_conv\n",
      "497 block17_14\n",
      "498 block17_14_ac\n",
      "499 conv2d_228\n",
      "500 batch_normalization_228\n",
      "501 activation_228\n",
      "502 conv2d_229\n",
      "503 batch_normalization_229\n",
      "504 activation_229\n",
      "505 conv2d_227\n",
      "506 conv2d_230\n",
      "507 batch_normalization_227\n",
      "508 batch_normalization_230\n",
      "509 activation_227\n",
      "510 activation_230\n",
      "511 block17_15_mixed\n",
      "512 block17_15_conv\n",
      "513 block17_15\n",
      "514 block17_15_ac\n",
      "515 conv2d_232\n",
      "516 batch_normalization_232\n",
      "517 activation_232\n",
      "518 conv2d_233\n",
      "519 batch_normalization_233\n",
      "520 activation_233\n",
      "521 conv2d_231\n",
      "522 conv2d_234\n",
      "523 batch_normalization_231\n",
      "524 batch_normalization_234\n",
      "525 activation_231\n",
      "526 activation_234\n",
      "527 block17_16_mixed\n",
      "528 block17_16_conv\n",
      "529 block17_16\n",
      "530 block17_16_ac\n",
      "531 conv2d_236\n",
      "532 batch_normalization_236\n",
      "533 activation_236\n",
      "534 conv2d_237\n",
      "535 batch_normalization_237\n",
      "536 activation_237\n",
      "537 conv2d_235\n",
      "538 conv2d_238\n",
      "539 batch_normalization_235\n",
      "540 batch_normalization_238\n",
      "541 activation_235\n",
      "542 activation_238\n",
      "543 block17_17_mixed\n",
      "544 block17_17_conv\n",
      "545 block17_17\n",
      "546 block17_17_ac\n",
      "547 conv2d_240\n",
      "548 batch_normalization_240\n",
      "549 activation_240\n",
      "550 conv2d_241\n",
      "551 batch_normalization_241\n",
      "552 activation_241\n",
      "553 conv2d_239\n",
      "554 conv2d_242\n",
      "555 batch_normalization_239\n",
      "556 batch_normalization_242\n",
      "557 activation_239\n",
      "558 activation_242\n",
      "559 block17_18_mixed\n",
      "560 block17_18_conv\n",
      "561 block17_18\n",
      "562 block17_18_ac\n",
      "563 conv2d_244\n",
      "564 batch_normalization_244\n",
      "565 activation_244\n",
      "566 conv2d_245\n",
      "567 batch_normalization_245\n",
      "568 activation_245\n",
      "569 conv2d_243\n",
      "570 conv2d_246\n",
      "571 batch_normalization_243\n",
      "572 batch_normalization_246\n",
      "573 activation_243\n",
      "574 activation_246\n",
      "575 block17_19_mixed\n",
      "576 block17_19_conv\n",
      "577 block17_19\n",
      "578 block17_19_ac\n",
      "579 conv2d_248\n",
      "580 batch_normalization_248\n",
      "581 activation_248\n",
      "582 conv2d_249\n",
      "583 batch_normalization_249\n",
      "584 activation_249\n",
      "585 conv2d_247\n",
      "586 conv2d_250\n",
      "587 batch_normalization_247\n",
      "588 batch_normalization_250\n",
      "589 activation_247\n",
      "590 activation_250\n",
      "591 block17_20_mixed\n",
      "592 block17_20_conv\n",
      "593 block17_20\n",
      "594 block17_20_ac\n",
      "595 conv2d_255\n",
      "596 batch_normalization_255\n",
      "597 activation_255\n",
      "598 conv2d_251\n",
      "599 conv2d_253\n",
      "600 conv2d_256\n",
      "601 batch_normalization_251\n",
      "602 batch_normalization_253\n",
      "603 batch_normalization_256\n",
      "604 activation_251\n",
      "605 activation_253\n",
      "606 activation_256\n",
      "607 conv2d_252\n",
      "608 conv2d_254\n",
      "609 conv2d_257\n",
      "610 batch_normalization_252\n",
      "611 batch_normalization_254\n",
      "612 batch_normalization_257\n",
      "613 activation_252\n",
      "614 activation_254\n",
      "615 activation_257\n",
      "616 max_pooling2d_8\n",
      "617 mixed_7a\n",
      "618 conv2d_259\n",
      "619 batch_normalization_259\n",
      "620 activation_259\n",
      "621 conv2d_260\n",
      "622 batch_normalization_260\n",
      "623 activation_260\n",
      "624 conv2d_258\n",
      "625 conv2d_261\n",
      "626 batch_normalization_258\n",
      "627 batch_normalization_261\n",
      "628 activation_258\n",
      "629 activation_261\n",
      "630 block8_1_mixed\n",
      "631 block8_1_conv\n",
      "632 block8_1\n",
      "633 block8_1_ac\n",
      "634 conv2d_263\n",
      "635 batch_normalization_263\n",
      "636 activation_263\n",
      "637 conv2d_264\n",
      "638 batch_normalization_264\n",
      "639 activation_264\n",
      "640 conv2d_262\n",
      "641 conv2d_265\n",
      "642 batch_normalization_262\n",
      "643 batch_normalization_265\n",
      "644 activation_262\n",
      "645 activation_265\n",
      "646 block8_2_mixed\n",
      "647 block8_2_conv\n",
      "648 block8_2\n",
      "649 block8_2_ac\n",
      "650 conv2d_267\n",
      "651 batch_normalization_267\n",
      "652 activation_267\n",
      "653 conv2d_268\n",
      "654 batch_normalization_268\n",
      "655 activation_268\n",
      "656 conv2d_266\n",
      "657 conv2d_269\n",
      "658 batch_normalization_266\n",
      "659 batch_normalization_269\n",
      "660 activation_266\n",
      "661 activation_269\n",
      "662 block8_3_mixed\n",
      "663 block8_3_conv\n",
      "664 block8_3\n",
      "665 block8_3_ac\n",
      "666 conv2d_271\n",
      "667 batch_normalization_271\n",
      "668 activation_271\n",
      "669 conv2d_272\n",
      "670 batch_normalization_272\n",
      "671 activation_272\n",
      "672 conv2d_270\n",
      "673 conv2d_273\n",
      "674 batch_normalization_270\n",
      "675 batch_normalization_273\n",
      "676 activation_270\n",
      "677 activation_273\n",
      "678 block8_4_mixed\n",
      "679 block8_4_conv\n",
      "680 block8_4\n",
      "681 block8_4_ac\n",
      "682 conv2d_275\n",
      "683 batch_normalization_275\n",
      "684 activation_275\n",
      "685 conv2d_276\n",
      "686 batch_normalization_276\n",
      "687 activation_276\n",
      "688 conv2d_274\n",
      "689 conv2d_277\n",
      "690 batch_normalization_274\n",
      "691 batch_normalization_277\n",
      "692 activation_274\n",
      "693 activation_277\n",
      "694 block8_5_mixed\n",
      "695 block8_5_conv\n",
      "696 block8_5\n",
      "697 block8_5_ac\n",
      "698 conv2d_279\n",
      "699 batch_normalization_279\n",
      "700 activation_279\n",
      "701 conv2d_280\n",
      "702 batch_normalization_280\n",
      "703 activation_280\n",
      "704 conv2d_278\n",
      "705 conv2d_281\n",
      "706 batch_normalization_278\n",
      "707 batch_normalization_281\n",
      "708 activation_278\n",
      "709 activation_281\n",
      "710 block8_6_mixed\n",
      "711 block8_6_conv\n",
      "712 block8_6\n",
      "713 block8_6_ac\n",
      "714 conv2d_283\n",
      "715 batch_normalization_283\n",
      "716 activation_283\n",
      "717 conv2d_284\n",
      "718 batch_normalization_284\n",
      "719 activation_284\n",
      "720 conv2d_282\n",
      "721 conv2d_285\n",
      "722 batch_normalization_282\n",
      "723 batch_normalization_285\n",
      "724 activation_282\n",
      "725 activation_285\n",
      "726 block8_7_mixed\n",
      "727 block8_7_conv\n",
      "728 block8_7\n",
      "729 block8_7_ac\n",
      "730 conv2d_287\n",
      "731 batch_normalization_287\n",
      "732 activation_287\n",
      "733 conv2d_288\n",
      "734 batch_normalization_288\n",
      "735 activation_288\n",
      "736 conv2d_286\n",
      "737 conv2d_289\n",
      "738 batch_normalization_286\n",
      "739 batch_normalization_289\n",
      "740 activation_286\n",
      "741 activation_289\n",
      "742 block8_8_mixed\n",
      "743 block8_8_conv\n",
      "744 block8_8\n",
      "745 block8_8_ac\n",
      "746 conv2d_291\n",
      "747 batch_normalization_291\n",
      "748 activation_291\n",
      "749 conv2d_292\n",
      "750 batch_normalization_292\n",
      "751 activation_292\n",
      "752 conv2d_290\n",
      "753 conv2d_293\n",
      "754 batch_normalization_290\n",
      "755 batch_normalization_293\n",
      "756 activation_290\n",
      "757 activation_293\n",
      "758 block8_9_mixed\n",
      "759 block8_9_conv\n",
      "760 block8_9\n",
      "761 block8_9_ac\n",
      "762 conv2d_295\n",
      "763 batch_normalization_295\n",
      "764 activation_295\n",
      "765 conv2d_296\n",
      "766 batch_normalization_296\n",
      "767 activation_296\n",
      "768 conv2d_294\n",
      "769 conv2d_297\n",
      "770 batch_normalization_294\n",
      "771 batch_normalization_297\n",
      "772 activation_294\n",
      "773 activation_297\n",
      "774 block8_10_mixed\n",
      "775 block8_10_conv\n",
      "776 block8_10\n",
      "777 conv_7b\n",
      "778 conv_7b_bn\n",
      "779 conv_7b_ac\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "463/462 [==============================] - 249s 538ms/step - loss: 1.8827 - acc: 0.5618 - val_loss: 1.4449 - val_acc: 0.6586\n",
      "Epoch 2/30\n",
      "463/462 [==============================] - 225s 486ms/step - loss: 1.1246 - acc: 0.7152 - val_loss: 1.2406 - val_acc: 0.7043\n",
      "Epoch 3/30\n",
      "463/462 [==============================] - 225s 486ms/step - loss: 0.8536 - acc: 0.7740 - val_loss: 1.2254 - val_acc: 0.7179\n",
      "Epoch 4/30\n",
      "463/462 [==============================] - 225s 487ms/step - loss: 0.6785 - acc: 0.8189 - val_loss: 1.1927 - val_acc: 0.7335\n",
      "Epoch 5/30\n",
      "463/462 [==============================] - 225s 486ms/step - loss: 0.5486 - acc: 0.8500 - val_loss: 1.2124 - val_acc: 0.7247\n",
      "Epoch 6/30\n",
      "463/462 [==============================] - 225s 486ms/step - loss: 0.4598 - acc: 0.8727 - val_loss: 1.2334 - val_acc: 0.7247\n",
      "Epoch 7/30\n",
      "463/462 [==============================] - 225s 486ms/step - loss: 0.4006 - acc: 0.8846 - val_loss: 1.3307 - val_acc: 0.7033\n",
      "Epoch 8/30\n",
      "463/462 [==============================] - 225s 486ms/step - loss: 0.3421 - acc: 0.9012 - val_loss: 1.3250 - val_acc: 0.7296\n",
      "Epoch 9/30\n",
      "463/462 [==============================] - 225s 486ms/step - loss: 0.3047 - acc: 0.9132 - val_loss: 1.3632 - val_acc: 0.7267\n",
      "Epoch 10/30\n",
      "463/462 [==============================] - 225s 486ms/step - loss: 0.2635 - acc: 0.9206 - val_loss: 1.3884 - val_acc: 0.7208\n",
      "Epoch 11/30\n",
      "463/462 [==============================] - 225s 486ms/step - loss: 0.2420 - acc: 0.9288 - val_loss: 1.3988 - val_acc: 0.7150\n",
      "Epoch 12/30\n",
      "463/462 [==============================] - 225s 486ms/step - loss: 0.2324 - acc: 0.9323 - val_loss: 1.4727 - val_acc: 0.7189\n",
      "Epoch 13/30\n",
      "463/462 [==============================] - 225s 486ms/step - loss: 0.2139 - acc: 0.9374 - val_loss: 1.4974 - val_acc: 0.7140\n",
      "Epoch 14/30\n",
      "463/462 [==============================] - 225s 486ms/step - loss: 0.1931 - acc: 0.9422 - val_loss: 1.5419 - val_acc: 0.7150\n",
      "Epoch 15/30\n",
      "463/462 [==============================] - 225s 486ms/step - loss: 0.1882 - acc: 0.9454 - val_loss: 1.4930 - val_acc: 0.7179\n",
      "Epoch 16/30\n",
      "463/462 [==============================] - 225s 486ms/step - loss: 0.1702 - acc: 0.9497 - val_loss: 1.5631 - val_acc: 0.7179\n",
      "Epoch 17/30\n",
      "463/462 [==============================] - 225s 485ms/step - loss: 0.1607 - acc: 0.9533 - val_loss: 1.5291 - val_acc: 0.7276\n",
      "Epoch 18/30\n",
      "463/462 [==============================] - 225s 486ms/step - loss: 0.1508 - acc: 0.9541 - val_loss: 1.6081 - val_acc: 0.7101\n",
      "Epoch 19/30\n",
      "463/462 [==============================] - 225s 486ms/step - loss: 0.1598 - acc: 0.9520 - val_loss: 1.5886 - val_acc: 0.7160\n",
      "Epoch 20/30\n",
      "463/462 [==============================] - 225s 486ms/step - loss: 0.1474 - acc: 0.9558 - val_loss: 1.5343 - val_acc: 0.7208\n",
      "Epoch 21/30\n",
      "463/462 [==============================] - 225s 486ms/step - loss: 0.1309 - acc: 0.9605 - val_loss: 1.6192 - val_acc: 0.7208\n",
      "Epoch 22/30\n",
      "463/462 [==============================] - 225s 486ms/step - loss: 0.1307 - acc: 0.9607 - val_loss: 1.6476 - val_acc: 0.7198\n",
      "Epoch 23/30\n",
      "463/462 [==============================] - 225s 486ms/step - loss: 0.1314 - acc: 0.9606 - val_loss: 1.5573 - val_acc: 0.7276\n",
      "Epoch 24/30\n",
      "463/462 [==============================] - 225s 486ms/step - loss: 0.1226 - acc: 0.9630 - val_loss: 1.6265 - val_acc: 0.7072\n",
      "Epoch 25/30\n",
      "463/462 [==============================] - 225s 485ms/step - loss: 0.1185 - acc: 0.9636 - val_loss: 1.7588 - val_acc: 0.7053\n",
      "Epoch 26/30\n",
      "463/462 [==============================] - 225s 486ms/step - loss: 0.1118 - acc: 0.9657 - val_loss: 1.7262 - val_acc: 0.7121\n",
      "Epoch 27/30\n",
      "463/462 [==============================] - 225s 486ms/step - loss: 0.1152 - acc: 0.9662 - val_loss: 1.7283 - val_acc: 0.7111\n",
      "Epoch 28/30\n",
      "463/462 [==============================] - 225s 486ms/step - loss: 0.1121 - acc: 0.9668 - val_loss: 1.6804 - val_acc: 0.7023\n",
      "Epoch 29/30\n",
      "463/462 [==============================] - 225s 486ms/step - loss: 0.1041 - acc: 0.9684 - val_loss: 1.7268 - val_acc: 0.7160\n",
      "Epoch 30/30\n",
      "463/462 [==============================] - 225s 486ms/step - loss: 0.1121 - acc: 0.9666 - val_loss: 1.6555 - val_acc: 0.7150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2bcd4a91e10>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name)\n",
    "\n",
    "for layer in model.layers[:249]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "time.sleep(100)\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(generator.flow(X_train, y_train.values, batch_size=batch_size),len(X_train) / batch_size, epochs=30,verbose=1,validation_data=(X_test, y_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.save('inceptionresnet_model.h5') \n",
    "del model  \n",
    "model = load_model('inceptionresnet_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1028/1028 [==============================] - 5s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.655475185697777, 0.71498054474708173]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x = X_test, y = y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Accuracy: 71%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
